{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open-clip-torch\n",
      "  Downloading open_clip_torch-2.31.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from open-clip-torch) (2.5.0+cu118)\n",
      "Requirement already satisfied: torchvision in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from open-clip-torch) (0.20.0+cu118)\n",
      "Requirement already satisfied: regex in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from open-clip-torch) (2024.11.6)\n",
      "Collecting ftfy (from open-clip-torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from open-clip-torch) (4.67.1)\n",
      "Collecting huggingface-hub (from open-clip-torch)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from open-clip-torch)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting timm (from open-clip-torch)\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: filelock in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (1.8.1)\n",
      "Requirement already satisfied: jinja2 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torch>=1.9.0->open-clip-torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.9.0->open-clip-torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from ftfy->open-clip-torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from huggingface-hub->open-clip-torch) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from huggingface-hub->open-clip-torch) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torchvision->open-clip-torch) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from torchvision->open-clip-torch) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/project/anaconda3/envs/latentconst/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch) (2025.1.31)\n",
      "Downloading open_clip_torch-2.31.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, ftfy, huggingface-hub, timm, open-clip-torch\n",
      "Successfully installed ftfy-6.3.1 huggingface-hub-0.29.3 open-clip-torch-2.31.0 safetensors-0.5.3 timm-1.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopen_clip\u001b[39;00m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model, _, preprocess \u001b[38;5;241m=\u001b[39m \u001b[43mopen_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_and_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViT-B-32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlaion2b_s34b_b79k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# model in train mode by default, impacts some models with BatchNorm or stochastic depth active\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m open_clip\u001b[38;5;241m.\u001b[39mget_tokenizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViT-B-32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k').to(device)\n",
    "model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "\n",
    "image = preprocess(Image.open(\"docs/CLIP.png\")).unsqueeze(0)\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"])\n",
    "\n",
    "with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latentconst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
